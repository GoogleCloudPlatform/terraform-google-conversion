// ----------------------------------------------------------------------------
//
//     ***     AUTO GENERATED CODE    ***    Type: MMv1     ***
//
// ----------------------------------------------------------------------------
//
//     This file is automatically generated by Magic Modules and manual
//     changes will be clobbered when the file is regenerated.
//
//     Please read more about how to change this file in
//     .github/CONTRIBUTING.md.
//
// ----------------------------------------------------------------------------

package dataproc_test

import (
	"os"
	"testing"

	"github.com/GoogleCloudPlatform/terraform-google-conversion/v7/test"
)

func TestAccDataprocBatch(t *testing.T) {
	if os.Getenv("WRITE_FILES") != "" {
		t.Parallel()
	}
	tests := []test.TestCase{
		{
			Name: "TestAccDataprocBatch_dataprocBatchSparkExample",
		},
		{
			Name: "TestAccDataprocBatch_dataprocBatchSparkFullExample",
		},
		{
			Name: "TestAccDataprocBatch_dataprocBatchSparksqlExample",
		},
		{
			Name: "TestAccDataprocBatch_dataprocBatchPysparkExample",
		},
		{
			Name: "TestAccDataprocBatch_dataprocBatchSparkrExample",
		},
		{
			Name: "TestAccDataprocBatch_dataprocBatchAutotuningExample",
		},
	}

	for _, tt := range tests {
		tt := tt

		t.Run(tt.Name, func(t *testing.T) {
			t.Parallel()

			if tt.Skip != "" {
				t.Skipf("Skipping %s test case: This case is currently disabled due to Issue.", tt.Name)
			}

			test.BidirectionalConversion(
				t,
				[]string{
					"batch_id",
					"count",
					"depends_on",
					"environment_config.execution_config.ttl",
					"for_each",
					"lifecycle",
					"location",
					"provider",
					"pyspark_batch.args",
					"runtime_config.0.properties",
					"spark_batch.args",
					"spark_r_batch.args",
					"spark_sql_batch.query_variables",
					"timeouts",
				},
				"google_dataproc_batch",
			)
		})
	}
}
