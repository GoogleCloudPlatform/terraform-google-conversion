// ----------------------------------------------------------------------------
//
//     ***     AUTO GENERATED CODE    ***    Type: MMv1     ***
//
// ----------------------------------------------------------------------------
//
//     This code is generated by Magic Modules using the following:
//
//     Configuration: https://github.com/GoogleCloudPlatform/magic-modules/tree/main/mmv1/products/dataproc/Batch.yaml
//     Template:      https://github.com/GoogleCloudPlatform/magic-modules/tree/main/mmv1/templates/tgc_next/cai2hcl/resource_converter.go.tmpl
//
//     DO NOT EDIT this file directly. Any changes made to this file will be
//     overwritten during the next generation cycle.
//
// ----------------------------------------------------------------------------

package dataproc

import (
	"crypto/sha256"
	"encoding/hex"
	"fmt"
	"log"
	"reflect"
	"regexp"
	"strings"

	"github.com/hashicorp/terraform-plugin-sdk/v2/diag"
	"github.com/hashicorp/terraform-plugin-sdk/v2/helper/customdiff"
	"github.com/hashicorp/terraform-plugin-sdk/v2/helper/id"
	"github.com/hashicorp/terraform-plugin-sdk/v2/helper/logging"
	"github.com/hashicorp/terraform-plugin-sdk/v2/helper/retry"
	"github.com/hashicorp/terraform-plugin-sdk/v2/helper/schema"
	"github.com/hashicorp/terraform-plugin-sdk/v2/helper/structure"
	"github.com/hashicorp/terraform-plugin-sdk/v2/helper/validation"
	"github.com/hashicorp/terraform-plugin-sdk/v2/terraform"

	"github.com/GoogleCloudPlatform/terraform-google-conversion/v7/pkg/cai2hcl/converters/utils"
	"github.com/GoogleCloudPlatform/terraform-google-conversion/v7/pkg/cai2hcl/models"
	"github.com/GoogleCloudPlatform/terraform-google-conversion/v7/pkg/caiasset"
	"github.com/GoogleCloudPlatform/terraform-google-conversion/v7/pkg/tgcresource"
	"github.com/GoogleCloudPlatform/terraform-google-conversion/v7/pkg/tpgresource"
	"github.com/GoogleCloudPlatform/terraform-google-conversion/v7/pkg/transport"
	transport_tpg "github.com/GoogleCloudPlatform/terraform-google-conversion/v7/pkg/transport"
	"github.com/GoogleCloudPlatform/terraform-google-conversion/v7/pkg/verify"

	"google.golang.org/api/googleapi"
)

var (
	_ = fmt.Sprintf
	_ = reflect.ValueOf
	_ = strings.Trim
	_ = diag.Diagnostic{}
	_ = customdiff.All
	_ = id.UniqueId
	_ = logging.LogLevel
	_ = log.Printf
	_ = retry.Retry
	_ = schema.Noop
	_ = structure.ExpandJsonFromString
	_ = validation.All
	_ = terraform.State{}
	_ = tgcresource.RemoveTerraformAttributionLabel
	_ = tpgresource.GetRegion
	_ = transport_tpg.Config{}
	_ = verify.ProjectRegex
	_ = googleapi.Error{}
)

type DataprocBatchCai2hclConverter struct {
	name   string
	schema map[string]*schema.Schema
}

func NewDataprocBatchCai2hclConverter(provider *schema.Provider) models.Cai2hclConverter {
	schema := provider.ResourcesMap[DataprocBatchSchemaName].Schema

	return &DataprocBatchCai2hclConverter{
		name:   DataprocBatchSchemaName,
		schema: schema,
	}
}

// Convert converts asset to HCL resource blocks.
func (c *DataprocBatchCai2hclConverter) Convert(asset caiasset.Asset) ([]*models.TerraformResourceBlock, error) {
	var blocks []*models.TerraformResourceBlock
	block, err := c.convertResourceData(asset)
	if err != nil {
		return nil, err
	}
	blocks = append(blocks, block)
	return blocks, nil
}

func (c *DataprocBatchCai2hclConverter) convertResourceData(asset caiasset.Asset) (*models.TerraformResourceBlock, error) {
	if asset.Resource == nil || asset.Resource.Data == nil {
		return nil, fmt.Errorf("asset resource data is nil")
	}

	var err error
	res := asset.Resource.Data
	config := transport.NewConfig()

	// This is a fake resource used to get fake d
	// d.Get will return empty map, instead of nil
	fakeResource := &schema.Resource{
		Schema: c.schema,
	}
	d := fakeResource.TestResourceData()

	assetNameParts := strings.Split(asset.Name, "/")

	hclBlockName := assetNameParts[len(assetNameParts)-1]
	digitRegex := regexp.MustCompile(`^\d+$`)
	nameValidator := regexp.MustCompile("^[a-zA-Z_][a-zA-Z0-9_-]*$")
	if digitRegex.MatchString(hclBlockName) || !nameValidator.MatchString(hclBlockName) {
		hasher := sha256.New()
		hasher.Write([]byte(hclBlockName))
		fullHash := hex.EncodeToString(hasher.Sum(nil))
		hclBlockName = fmt.Sprintf("resource%s", fullHash[:8])
	}
	hclData := make(map[string]interface{})

	outputFields := map[string]struct{}{"create_time": struct{}{}, "creator": struct{}{}, "effective_labels": struct{}{}, "name": struct{}{}, "operation": struct{}{}, "runtime_info": struct{}{}, "state": struct{}{}, "state_history": struct{}{}, "state_message": struct{}{}, "state_time": struct{}{}, "terraform_labels": struct{}{}, "uuid": struct{}{}}
	utils.ParseUrlParamValuesFromAssetName(asset.Name, "//dataproc.googleapis.com/projects/{{project}}/locations/{{location}}/batches/{{batch_id}}", outputFields, hclData)

	hclData["labels"] = flattenDataprocBatchLabels(res["labels"], d, config)
	hclData["runtime_config"] = flattenDataprocBatchRuntimeConfig(res["runtimeConfig"], d, config)
	hclData["environment_config"] = flattenDataprocBatchEnvironmentConfig(res["environmentConfig"], d, config)
	hclData["pyspark_batch"] = flattenDataprocBatchPysparkBatch(res["pysparkBatch"], d, config)
	hclData["spark_batch"] = flattenDataprocBatchSparkBatch(res["sparkBatch"], d, config)
	hclData["spark_r_batch"] = flattenDataprocBatchSparkRBatch(res["sparkRBatch"], d, config)
	hclData["spark_sql_batch"] = flattenDataprocBatchSparkSqlBatch(res["sparkSqlBatch"], d, config)

	ctyVal, err := utils.MapToCtyValWithSchema(hclData, c.schema)
	if err != nil {
		return nil, err
	}
	return &models.TerraformResourceBlock{
		Labels: []string{c.name, hclBlockName},
		Value:  ctyVal,
	}, nil
}

func flattenDataprocBatchLabels(v interface{}, d *schema.ResourceData, config *transport_tpg.Config) interface{} {
	return tgcresource.RemoveTerraformAttributionLabel(v)
}
func flattenDataprocBatchRuntimeConfig(v interface{}, d *schema.ResourceData, config *transport_tpg.Config) interface{} {
	if v == nil {
		return nil
	}
	original := v.(map[string]interface{})
	if len(original) == 0 {
		return nil
	}
	transformed := make(map[string]interface{})
	transformed["version"] =
		flattenDataprocBatchRuntimeConfigVersion(original["version"], d, config)
	transformed["container_image"] =
		flattenDataprocBatchRuntimeConfigContainerImage(original["containerImage"], d, config)
	transformed["properties"] =
		flattenDataprocBatchRuntimeConfigProperties(original["properties"], d, config)
	transformed["autotuning_config"] =
		flattenDataprocBatchRuntimeConfigAutotuningConfig(original["autotuningConfig"], d, config)
	transformed["cohort"] =
		flattenDataprocBatchRuntimeConfigCohort(original["cohort"], d, config)
	if tgcresource.AllValuesAreNil(transformed) {
		return nil
	}
	return []interface{}{transformed}
}

func flattenDataprocBatchRuntimeConfigVersion(v interface{}, d *schema.ResourceData, config *transport_tpg.Config) interface{} {
	return v
}

func flattenDataprocBatchRuntimeConfigContainerImage(v interface{}, d *schema.ResourceData, config *transport_tpg.Config) interface{} {
	return v
}

func flattenDataprocBatchRuntimeConfigProperties(v interface{}, d *schema.ResourceData, config *transport_tpg.Config) interface{} {
	if properties, ok := v.(map[string]interface{}); ok {
		propertiesCopy := make(map[string]interface{})
		for k, v := range properties {
			// Remove the prefix "spark:" from the properties. Otherwise, terraform apply will fail with the error from API.
			modifiedK := strings.TrimPrefix(k, "spark:")
			propertiesCopy[modifiedK] = v
		}
		return propertiesCopy
	}

	return v
}

func flattenDataprocBatchRuntimeConfigAutotuningConfig(v interface{}, d *schema.ResourceData, config *transport_tpg.Config) interface{} {
	if v == nil {
		return nil
	}
	original := v.(map[string]interface{})
	if len(original) == 0 {
		return nil
	}
	transformed := make(map[string]interface{})
	transformed["scenarios"] =
		flattenDataprocBatchRuntimeConfigAutotuningConfigScenarios(original["scenarios"], d, config)
	if tgcresource.AllValuesAreNil(transformed) {
		return nil
	}
	return []interface{}{transformed}
}

func flattenDataprocBatchRuntimeConfigAutotuningConfigScenarios(v interface{}, d *schema.ResourceData, config *transport_tpg.Config) interface{} {
	return v
}

func flattenDataprocBatchRuntimeConfigCohort(v interface{}, d *schema.ResourceData, config *transport_tpg.Config) interface{} {
	return v
}

func flattenDataprocBatchEnvironmentConfig(v interface{}, d *schema.ResourceData, config *transport_tpg.Config) interface{} {
	if v == nil {
		return nil
	}
	original := v.(map[string]interface{})
	if len(original) == 0 {
		return nil
	}
	transformed := make(map[string]interface{})
	transformed["execution_config"] =
		flattenDataprocBatchEnvironmentConfigExecutionConfig(original["executionConfig"], d, config)
	transformed["peripherals_config"] =
		flattenDataprocBatchEnvironmentConfigPeripheralsConfig(original["peripheralsConfig"], d, config)
	if tgcresource.AllValuesAreNil(transformed) {
		return nil
	}
	return []interface{}{transformed}
}

func flattenDataprocBatchEnvironmentConfigExecutionConfig(v interface{}, d *schema.ResourceData, config *transport_tpg.Config) interface{} {
	if v == nil {
		return nil
	}
	original := v.(map[string]interface{})
	if len(original) == 0 {
		return nil
	}
	transformed := make(map[string]interface{})
	transformed["service_account"] =
		flattenDataprocBatchEnvironmentConfigExecutionConfigServiceAccount(original["serviceAccount"], d, config)
	transformed["network_tags"] =
		flattenDataprocBatchEnvironmentConfigExecutionConfigNetworkTags(original["networkTags"], d, config)
	transformed["kms_key"] =
		flattenDataprocBatchEnvironmentConfigExecutionConfigKmsKey(original["kmsKey"], d, config)
	transformed["ttl"] =
		flattenDataprocBatchEnvironmentConfigExecutionConfigTtl(original["ttl"], d, config)
	transformed["staging_bucket"] =
		flattenDataprocBatchEnvironmentConfigExecutionConfigStagingBucket(original["stagingBucket"], d, config)
	transformed["network_uri"] =
		flattenDataprocBatchEnvironmentConfigExecutionConfigNetworkUri(original["networkUri"], d, config)
	transformed["subnetwork_uri"] =
		flattenDataprocBatchEnvironmentConfigExecutionConfigSubnetworkUri(original["subnetworkUri"], d, config)
	transformed["authentication_config"] =
		flattenDataprocBatchEnvironmentConfigExecutionConfigAuthenticationConfig(original["authenticationConfig"], d, config)
	if tgcresource.AllValuesAreNil(transformed) {
		return nil
	}
	return []interface{}{transformed}
}

func flattenDataprocBatchEnvironmentConfigExecutionConfigServiceAccount(v interface{}, d *schema.ResourceData, config *transport_tpg.Config) interface{} {
	return v
}

func flattenDataprocBatchEnvironmentConfigExecutionConfigNetworkTags(v interface{}, d *schema.ResourceData, config *transport_tpg.Config) interface{} {
	return v
}

func flattenDataprocBatchEnvironmentConfigExecutionConfigKmsKey(v interface{}, d *schema.ResourceData, config *transport_tpg.Config) interface{} {
	return v
}

func flattenDataprocBatchEnvironmentConfigExecutionConfigTtl(v interface{}, d *schema.ResourceData, config *transport_tpg.Config) interface{} {
	return v
}

func flattenDataprocBatchEnvironmentConfigExecutionConfigStagingBucket(v interface{}, d *schema.ResourceData, config *transport_tpg.Config) interface{} {
	return v
}

func flattenDataprocBatchEnvironmentConfigExecutionConfigNetworkUri(v interface{}, d *schema.ResourceData, config *transport_tpg.Config) interface{} {
	return v
}

func flattenDataprocBatchEnvironmentConfigExecutionConfigSubnetworkUri(v interface{}, d *schema.ResourceData, config *transport_tpg.Config) interface{} {
	return v
}

func flattenDataprocBatchEnvironmentConfigExecutionConfigAuthenticationConfig(v interface{}, d *schema.ResourceData, config *transport_tpg.Config) interface{} {
	if v == nil {
		return nil
	}
	original := v.(map[string]interface{})
	if len(original) == 0 {
		return nil
	}
	transformed := make(map[string]interface{})
	transformed["user_workload_authentication_type"] =
		flattenDataprocBatchEnvironmentConfigExecutionConfigAuthenticationConfigUserWorkloadAuthenticationType(original["userWorkloadAuthenticationType"], d, config)
	if tgcresource.AllValuesAreNil(transformed) {
		return nil
	}
	return []interface{}{transformed}
}

func flattenDataprocBatchEnvironmentConfigExecutionConfigAuthenticationConfigUserWorkloadAuthenticationType(v interface{}, d *schema.ResourceData, config *transport_tpg.Config) interface{} {
	return v
}

func flattenDataprocBatchEnvironmentConfigPeripheralsConfig(v interface{}, d *schema.ResourceData, config *transport_tpg.Config) interface{} {
	if v == nil {
		return nil
	}
	original := v.(map[string]interface{})
	transformed := make(map[string]interface{})
	transformed["metastore_service"] =
		flattenDataprocBatchEnvironmentConfigPeripheralsConfigMetastoreService(original["metastoreService"], d, config)
	transformed["spark_history_server_config"] =
		flattenDataprocBatchEnvironmentConfigPeripheralsConfigSparkHistoryServerConfig(original["sparkHistoryServerConfig"], d, config)
	return []interface{}{transformed}
}

func flattenDataprocBatchEnvironmentConfigPeripheralsConfigMetastoreService(v interface{}, d *schema.ResourceData, config *transport_tpg.Config) interface{} {
	return v
}

func flattenDataprocBatchEnvironmentConfigPeripheralsConfigSparkHistoryServerConfig(v interface{}, d *schema.ResourceData, config *transport_tpg.Config) interface{} {
	if v == nil {
		return nil
	}
	original := v.(map[string]interface{})
	if len(original) == 0 {
		return nil
	}
	transformed := make(map[string]interface{})
	transformed["dataproc_cluster"] =
		flattenDataprocBatchEnvironmentConfigPeripheralsConfigSparkHistoryServerConfigDataprocCluster(original["dataprocCluster"], d, config)
	if tgcresource.AllValuesAreNil(transformed) {
		return nil
	}
	return []interface{}{transformed}
}

func flattenDataprocBatchEnvironmentConfigPeripheralsConfigSparkHistoryServerConfigDataprocCluster(v interface{}, d *schema.ResourceData, config *transport_tpg.Config) interface{} {
	return v
}

func flattenDataprocBatchPysparkBatch(v interface{}, d *schema.ResourceData, config *transport_tpg.Config) interface{} {
	if v == nil {
		return nil
	}
	original := v.(map[string]interface{})
	if len(original) == 0 {
		return nil
	}
	transformed := make(map[string]interface{})
	transformed["main_python_file_uri"] =
		flattenDataprocBatchPysparkBatchMainPythonFileUri(original["mainPythonFileUri"], d, config)
	transformed["args"] =
		flattenDataprocBatchPysparkBatchArgs(original["args"], d, config)
	transformed["python_file_uris"] =
		flattenDataprocBatchPysparkBatchPythonFileUris(original["pythonFileUris"], d, config)
	transformed["jar_file_uris"] =
		flattenDataprocBatchPysparkBatchJarFileUris(original["jarFileUris"], d, config)
	transformed["file_uris"] =
		flattenDataprocBatchPysparkBatchFileUris(original["fileUris"], d, config)
	transformed["archive_uris"] =
		flattenDataprocBatchPysparkBatchArchiveUris(original["archiveUris"], d, config)
	if tgcresource.AllValuesAreNil(transformed) {
		return nil
	}
	return []interface{}{transformed}
}

func flattenDataprocBatchPysparkBatchMainPythonFileUri(v interface{}, d *schema.ResourceData, config *transport_tpg.Config) interface{} {
	return v
}

func flattenDataprocBatchPysparkBatchArgs(v interface{}, d *schema.ResourceData, config *transport_tpg.Config) interface{} {
	return v
}

func flattenDataprocBatchPysparkBatchPythonFileUris(v interface{}, d *schema.ResourceData, config *transport_tpg.Config) interface{} {
	return v
}

func flattenDataprocBatchPysparkBatchJarFileUris(v interface{}, d *schema.ResourceData, config *transport_tpg.Config) interface{} {
	return v
}

func flattenDataprocBatchPysparkBatchFileUris(v interface{}, d *schema.ResourceData, config *transport_tpg.Config) interface{} {
	return v
}

func flattenDataprocBatchPysparkBatchArchiveUris(v interface{}, d *schema.ResourceData, config *transport_tpg.Config) interface{} {
	return v
}

func flattenDataprocBatchSparkBatch(v interface{}, d *schema.ResourceData, config *transport_tpg.Config) interface{} {
	if v == nil {
		return nil
	}
	original := v.(map[string]interface{})
	if len(original) == 0 {
		return nil
	}
	transformed := make(map[string]interface{})
	transformed["args"] =
		flattenDataprocBatchSparkBatchArgs(original["args"], d, config)
	transformed["jar_file_uris"] =
		flattenDataprocBatchSparkBatchJarFileUris(original["jarFileUris"], d, config)
	transformed["file_uris"] =
		flattenDataprocBatchSparkBatchFileUris(original["fileUris"], d, config)
	transformed["archive_uris"] =
		flattenDataprocBatchSparkBatchArchiveUris(original["archiveUris"], d, config)
	transformed["main_jar_file_uri"] =
		flattenDataprocBatchSparkBatchMainJarFileUri(original["mainJarFileUri"], d, config)
	transformed["main_class"] =
		flattenDataprocBatchSparkBatchMainClass(original["mainClass"], d, config)
	if tgcresource.AllValuesAreNil(transformed) {
		return nil
	}
	return []interface{}{transformed}
}

func flattenDataprocBatchSparkBatchArgs(v interface{}, d *schema.ResourceData, config *transport_tpg.Config) interface{} {
	return v
}

func flattenDataprocBatchSparkBatchJarFileUris(v interface{}, d *schema.ResourceData, config *transport_tpg.Config) interface{} {
	return v
}

func flattenDataprocBatchSparkBatchFileUris(v interface{}, d *schema.ResourceData, config *transport_tpg.Config) interface{} {
	return v
}

func flattenDataprocBatchSparkBatchArchiveUris(v interface{}, d *schema.ResourceData, config *transport_tpg.Config) interface{} {
	return v
}

func flattenDataprocBatchSparkBatchMainJarFileUri(v interface{}, d *schema.ResourceData, config *transport_tpg.Config) interface{} {
	return v
}

func flattenDataprocBatchSparkBatchMainClass(v interface{}, d *schema.ResourceData, config *transport_tpg.Config) interface{} {
	return v
}

func flattenDataprocBatchSparkRBatch(v interface{}, d *schema.ResourceData, config *transport_tpg.Config) interface{} {
	if v == nil {
		return nil
	}
	original := v.(map[string]interface{})
	if len(original) == 0 {
		return nil
	}
	transformed := make(map[string]interface{})
	transformed["main_r_file_uri"] =
		flattenDataprocBatchSparkRBatchMainRFileUri(original["mainRFileUri"], d, config)
	transformed["args"] =
		flattenDataprocBatchSparkRBatchArgs(original["args"], d, config)
	transformed["file_uris"] =
		flattenDataprocBatchSparkRBatchFileUris(original["fileUris"], d, config)
	transformed["archive_uris"] =
		flattenDataprocBatchSparkRBatchArchiveUris(original["archiveUris"], d, config)
	if tgcresource.AllValuesAreNil(transformed) {
		return nil
	}
	return []interface{}{transformed}
}

func flattenDataprocBatchSparkRBatchMainRFileUri(v interface{}, d *schema.ResourceData, config *transport_tpg.Config) interface{} {
	return v
}

func flattenDataprocBatchSparkRBatchArgs(v interface{}, d *schema.ResourceData, config *transport_tpg.Config) interface{} {
	return v
}

func flattenDataprocBatchSparkRBatchFileUris(v interface{}, d *schema.ResourceData, config *transport_tpg.Config) interface{} {
	return v
}

func flattenDataprocBatchSparkRBatchArchiveUris(v interface{}, d *schema.ResourceData, config *transport_tpg.Config) interface{} {
	return v
}

func flattenDataprocBatchSparkSqlBatch(v interface{}, d *schema.ResourceData, config *transport_tpg.Config) interface{} {
	if v == nil {
		return nil
	}
	original := v.(map[string]interface{})
	if len(original) == 0 {
		return nil
	}
	transformed := make(map[string]interface{})
	transformed["query_file_uri"] =
		flattenDataprocBatchSparkSqlBatchQueryFileUri(original["queryFileUri"], d, config)
	transformed["jar_file_uris"] =
		flattenDataprocBatchSparkSqlBatchJarFileUris(original["jarFileUris"], d, config)
	transformed["query_variables"] =
		flattenDataprocBatchSparkSqlBatchQueryVariables(original["queryVariables"], d, config)
	if tgcresource.AllValuesAreNil(transformed) {
		return nil
	}
	return []interface{}{transformed}
}

func flattenDataprocBatchSparkSqlBatchQueryFileUri(v interface{}, d *schema.ResourceData, config *transport_tpg.Config) interface{} {
	return v
}

func flattenDataprocBatchSparkSqlBatchJarFileUris(v interface{}, d *schema.ResourceData, config *transport_tpg.Config) interface{} {
	return v
}

func flattenDataprocBatchSparkSqlBatchQueryVariables(v interface{}, d *schema.ResourceData, config *transport_tpg.Config) interface{} {
	return v
}
